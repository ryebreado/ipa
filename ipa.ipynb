{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be269a92-d595-4c92-a525-d150faae1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/ipa-dict-master/data/en_US.txt\", sep=\"\\t\", header=None, keep_default_na=False)\n",
    "df.columns = [\"word_original\", \"ipa_original\"]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e282705-461f-4187-84bd-7b581b111035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df[\"word\"] = df[\"word_original\"].apply(str.lower)\n",
    "\n",
    "def normalize_ipa(ipa_original):\n",
    "    result = re.search(r\"/[^/]+/$\", ipa_original)\n",
    "    if result:\n",
    "        return result.group()[1:-1]\n",
    "    return ipa_original\n",
    "\n",
    "df[\"ipa\"] = df[\"ipa_original\"].apply(normalize_ipa)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be51ae-3eb7-4f88-b2cd-c7ce6736f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class Direction(Enum):\n",
    "    TO_IPA = 1\n",
    "    FROM_IPA = 2\n",
    "    \n",
    "class Sublanguage(Enum):\n",
    "    WORD = 1\n",
    "    IPA = 2\n",
    "\n",
    "@dataclass\n",
    "class Alphabet:\n",
    "    locale: str\n",
    "    sublanguage: Sublanguage\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.locale}:{self.sublanguage.name}\"\n",
    "\n",
    "LOCALE = \"en_US\"\n",
    "DIRECTION = Direction.TO_IPA\n",
    "\n",
    "SRC_SUBLANGUAGE = Sublanguage.WORD if DIRECTION == Direction.TO_IPA else Sublanguage.IPA\n",
    "TGT_SUBLANGUAGE = Sublanguage.IPA if DIRECTION == Direction.TO_IPA else Sublanguage.WORD\n",
    "\n",
    "SRC_LANGUAGE = Alphabet(LOCALE, SRC_SUBLANGUAGE)\n",
    "TGT_LANGUAGE = Alphabet(LOCALE, TGT_SUBLANGUAGE)\n",
    "\n",
    "print(f\"The model will translate {SRC_LANGUAGE} to {TGT_LANGUAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b930e-69bd-4924-a2d4-7b79b3876e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(filename):\n",
    "    df = pd.read_csv(filename, sep=\"\\t\", header=None, keep_default_na=False)\n",
    "    df.columns = [\"word_original\", \"ipa_original\"]\n",
    "    df[Sublanguage.WORD.name] = df[\"word_original\"].apply(str.lower)\n",
    "    df[Sublanguage.IPA.name] = df[\"ipa_original\"].apply(normalize_ipa)\n",
    "    return df\n",
    "\n",
    "df_en = create_dataframe(\"data/ipa-dict-master/data/en_US.txt\")\n",
    "display(df_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa520d6-fe4d-47f1-a65a-6cebde548d44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IpaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, locale: str, direction: Direction, label: str | None = None):\n",
    "        self._df = df\n",
    "        self._direction = direction\n",
    "        self._locale = locale\n",
    "        self._label = label\n",
    "    \n",
    "    def direction(self) -> Direction:\n",
    "        return self._direction\n",
    "    \n",
    "    def locale(self) -> str:\n",
    "        return self._locale\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "    \n",
    "    def __getitem__(self, idx) -> list[str]:\n",
    "        row = self._df.iloc[idx]\n",
    "        if self._direction == Direction.TO_IPA:\n",
    "            return [row[Sublanguage.WORD.name], row[Sublanguage.IPA.name]]\n",
    "        else:\n",
    "            return [row[Sublanguage.IPA.name], row[Sublanguage.WORD.name]]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        opt_label = f\"[{self._label}]\" if self._label else \"\"\n",
    "        return f\"IpaDataset{opt_label}(size={len(self)}, locale={self.locale()}, dir={self.direction().name})\"\n",
    "\n",
    "ipa_en = IpaDataset(df_en, \"en_US\", Direction.TO_IPA, \"b\")\n",
    "print(ipa_en)\n",
    "print(len(ipa_en))\n",
    "print(ipa_en[400])\n",
    "print(ipa_en[400:402])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8b5ae-c5cd-4a4e-85da-bbf1211fea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplit(Enum):\n",
    "    TRAIN = 1\n",
    "    VALIDATION = 2\n",
    "\n",
    "def tokenize(word: str) -> list[str]:\n",
    "    return list(word)\n",
    "\n",
    "class IpaDatasetHolder:\n",
    "    def __init__(self, \n",
    "                 locale: str, \n",
    "                 everything: pd.DataFrame,\n",
    "                 splits: dict[DataSplit, dict[Direction, IpaDataset]],\n",
    "                ):\n",
    "        self._locale = locale\n",
    "        self._everything = everything\n",
    "        self._splits = splits\n",
    "\n",
    "    def __getitem__(self, idx: tuple[DataSplit, Direction]) -> IpaDataset:\n",
    "        split, direction = idx\n",
    "        return self._splits[split][direction]\n",
    "\n",
    "    @classmethod\n",
    "    def create_holder_from_csv(cls, locale: str):\n",
    "        csv_path = f\"data/ipa-dict-master/data/{locale}.txt\"\n",
    "        df = create_dataframe(csv_path)\n",
    "        \n",
    "        df_train = df.sample(frac = 0.7)\n",
    "        df_validation = df.drop(df_train.index)\n",
    "        split_dfs = {DataSplit.TRAIN: df_train, DataSplit.VALIDATION: df_validation}\n",
    "        \n",
    "        splits = {}\n",
    "        for split, split_df in split_dfs.items():\n",
    "            splits[split] = {d:IpaDataset(split_df, locale, d, split.name) for d in Direction}\n",
    "\n",
    "        return cls(locale=locale, everything=df, splits=splits)\n",
    "    \n",
    "    def build_token_lists(self) -> dict[Sublanguage, list[str]]:\n",
    "        word_tokens = set()\n",
    "        ipa_tokens = set()\n",
    "        for _, row in self._everything.iterrows():\n",
    "            word_tokens.update(tokenize(row[Sublanguage.WORD.name]))\n",
    "            ipa_tokens.update(tokenize(row[Sublanguage.IPA.name]))\n",
    "        return {Sublanguage.WORD: sorted(word_tokens), Sublanguage.IPA: sorted(ipa_tokens)}\n",
    "                              \n",
    "\n",
    "en_holder = IpaDatasetHolder.create_holder_from_csv(\"en_US\")\n",
    "print(en_holder[DataSplit.TRAIN, Direction.TO_IPA])\n",
    "print(en_holder[DataSplit.VALIDATION, Direction.TO_IPA])\n",
    "token_lists_temp = en_holder.build_token_lists()\n",
    "print(token_lists_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d65b8-ba34-47ec-a83d-ae292420fcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
